{"cells":[{"cell_type":"code","execution_count":2,"id":"dcde4828-1cc7-4222-9e99-2aefe493da5a","metadata":{},"outputs":[],"source":["\n","import seaborn as sns, pandas as pd, numpy as np"]},{"cell_type":"markdown","id":"79efb3a0-e9fd-437c-b062-c6a54f0b9673","metadata":{},"source":["\n","\n","Importing the data from the file `Human_Activity_Recognition_Using_Smartphones_Data.csv` and examing the shape and data types. \n"]},{"cell_type":"code","execution_count":4,"id":"999cf066-82a2-43c1-9cdf-2fe8a1591775","metadata":{},"outputs":[],"source":["\n","data = pd.read_csv('Human_Activity_Recognition_Using_Smartphones_Data.csv', sep=',')"]},{"cell_type":"code","execution_count":5,"id":"075e58cb-5477-449e-a295-0519a2a38a30","metadata":{},"outputs":[{"data":{"text/plain":["(10299, 562)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"code","execution_count":6,"id":"db6de075-1c04-4a6a-91dc-6b11ada0009e","metadata":{},"outputs":[{"data":{"text/plain":["float64    561\n","object       1\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data.dtypes.value_counts()"]},{"cell_type":"code","execution_count":7,"id":"dd4520fc-da91-4558-8244-699d604aa23b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/yt/yy9gqhbd1f12h4vcpqpnhq400000gn/T/ipykernel_67016/1876261377.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  float_columns = (data.dtypes == np.float)\n"]}],"source":["# Mask to select float columns\n","float_columns = (data.dtypes == np.float)\n","\n","# Verify that the maximum of all float columns is 1.0\n","print( (data.loc[:,float_columns].max()==1.0).all() )\n","\n","# Verify that the minimum of all float columns is -1.0\n","print( (data.loc[:,float_columns].min()==-1.0).all() )\n"]},{"cell_type":"code","execution_count":8,"id":"1fb31427-d62a-4230-aee1-0e98e77376c4","metadata":{},"outputs":[{"data":{"text/plain":["array(['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS',\n","       'WALKING_UPSTAIRS'], dtype=object)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["\n","from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","\n","data['Activity'] = le.fit_transform(data['Activity'])\n","\n","le.classes_"]},{"cell_type":"code","execution_count":9,"id":"f45a4df3-66a6-43e7-a7b2-40fd266e54f0","metadata":{},"outputs":[{"data":{"text/plain":["array([2, 1, 0, 3, 4, 5])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data.Activity.unique()"]},{"cell_type":"code","execution_count":10,"id":"76b3b560-7705-4099-b7bf-8c834841220b","metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","feature_columns = [x for x in data.columns if x != 'Activity']\n","X_train, X_test, y_train, y_test = train_test_split(data[feature_columns], data['Activity'],\n","                 test_size=0.3, random_state=42)\n"]},{"cell_type":"code","execution_count":11,"id":"a222900d-5cf8-4ff3-8795-486044b6c439","metadata":{},"outputs":[{"data":{"text/plain":["((7209, 561), (7209,), (3090, 561), (3090,))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape, y_train.shape, X_test.shape, y_test.shape"]},{"cell_type":"markdown","id":"febacf8a-f986-4fbe-91c4-e766b1ba8877","metadata":{},"source":["\n","Fiting gradient boosted tree models with all parameters set to their defaults with the following tree numbers (`n_estimators = [15, 25, 50, 100, 200, 400]`) and evaluating the accuracy on the test data for each of these models.\n","Ploting the accuracy as a function of estimator number."]},{"cell_type":"code","execution_count":12,"id":"5fb195af-68c0-4d1a-a60e-3bf75bf761ac","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting model with 15 trees\n"]},{"name":"stderr","output_type":"stream","text":["/Users/rachelgupta/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Fitting model with 25 trees\n"]},{"name":"stderr","output_type":"stream","text":["/Users/rachelgupta/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Fitting model with 50 trees\n"]},{"name":"stderr","output_type":"stream","text":["/Users/rachelgupta/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Fitting model with 100 trees\n"]}],"source":["\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","\n","error_list = list()\n","\n","# Iterating through various possibilities for number of trees\n","tree_list = [15, 25, 50, 100, 200, 400]\n","for n_trees in tree_list:\n","    \n","    # Initializing the gradient boost classifier\n","    GBC = GradientBoostingClassifier(n_estimators=n_trees, random_state=42)\n","\n","    # Fiting the model\n","    print(f'Fitting model with {n_trees} trees')\n","    GBC.fit(X_train.values, y_train.values)\n","    y_pred = GBC.predict(X_test)\n","\n","    # the error\n","    error = 1.0 - accuracy_score(y_test, y_pred)\n","    error_list.append(pd.Series({'n_trees': n_trees, 'error': error}))\n","\n","error_df = pd.concat(error_list, axis=1).T.set_index('n_trees')\n","error_df"]},{"cell_type":"code","execution_count":null,"id":"8c866ed6-2175-4e71-9fe7-9a36a1f72c35","metadata":{},"outputs":[],"source":["# Plotting the result \n","sns.set_context('talk')\n","sns.set_style('white')\n","\n","ax = error_df.plot(marker='o', figsize=(12, 8), linewidth=5)\n","ax.set(xlabel='Number of Trees', ylabel='Error')\n","ax.set_xlim(0, max(error_df.index)*1.1);"]},{"cell_type":"markdown","id":"de694a6a-5a65-4f8e-b407-9b19b0614f58","metadata":{},"source":["Using a grid search with cross-validation, fiting a new gradient boosted classifier with the same list of estimators. Varying the learning rates (0.1, 0.01, 0.001, etc.), the subsampling value (1.0 or 0.5), and the number of maximum features (1, 2, etc.)."]},{"cell_type":"code","execution_count":null,"id":"387b550b-2fbc-433b-86c3-5c267d29835f","metadata":{},"outputs":[],"source":["\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {'n_estimators': tree_list,\n","              'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n","              'subsample': [1.0, 0.5],\n","              'max_features': [1, 2, 3, 4]}\n","\n","GV_GBC = GridSearchCV(GradientBoostingClassifier(random_state=42), \n","                      param_grid=param_grid, \n","                      scoring='accuracy',\n","                      n_jobs=-1)\n","\n","GV_GBC = GV_GBC.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"023c64d1-bf09-4558-9ca7-fb7b0d000da9","metadata":{},"outputs":[],"source":["# The best model\n","GV_GBC.best_estimator_"]},{"cell_type":"code","execution_count":null,"id":"2a4140df-9a09-4cbe-9637-9da8c1158b6d","metadata":{},"outputs":[],"source":["#!pip install -U scikit-learn"]},{"cell_type":"markdown","id":"1b8f8afd-17c9-4d98-ac67-e5524d12962c","metadata":{},"source":["The error metrics.\n"]},{"cell_type":"code","execution_count":null,"id":"3d9f6240-6f92-4a9d-aded-acce67afa4f4","metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","y_pred = GV_GBC.predict(X_test)\n","print(classification_report(y_pred, y_test))"]},{"cell_type":"markdown","id":"f2062b35-e11c-478f-852e-8e95891c7473","metadata":{},"source":["The confusion matrix.\n"]},{"cell_type":"code","execution_count":null,"id":"f6e70ab7-55bb-4400-83df-0834d8ed1c31","metadata":{},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred)\n","sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n","plt.show()"]},{"cell_type":"markdown","id":"7614310c-87bd-4289-bd16-f8e93250ae6a","metadata":{},"source":["Creating an AdaBoost model and fiting it using grid search. Tring a range of estimators between 100 and 200.\n","Comparing the errors from AdaBoost to those from the GradientBoostedClassifier.\n"]},{"cell_type":"code","execution_count":null,"id":"0e05dfee-6615-4158-b48f-b07f6efc3a4f","metadata":{},"outputs":[],"source":["from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n","\n","param_grid = {'n_estimators': [100, 150, 200],\n","              'learning_rate': [0.01, 0.001]}\n","\n","GV_ABC = GridSearchCV(ABC,\n","                      param_grid=param_grid, \n","                      scoring='accuracy',\n","                      n_jobs=-1)\n","\n","GV_ABC = GV_ABC.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"ebd20c79-3771-4249-b854-4c130e297ec6","metadata":{},"outputs":[],"source":["# The best model\n","GV_ABC.best_estimator_"]},{"cell_type":"markdown","id":"b1570e68-debe-423f-9094-64c30ed67d87","metadata":{},"source":["The error metrics. AdaBoost is very sensitive to outliers, so that could be the problem here.\n"]},{"cell_type":"code","execution_count":null,"id":"23739f0c-fccc-4751-8f70-87e75ea2ad69","metadata":{},"outputs":[],"source":["y_pred = GV_ABC.predict(X_test)\n","print(classification_report(y_pred, y_test))"]},{"cell_type":"code","execution_count":null,"id":"f3d318e6-805e-4d6c-990c-739c031f1007","metadata":{},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred)\n","sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n","plt.show()"]},{"cell_type":"markdown","id":"41a14e25-8353-49f6-8c1d-a30bcacf2452","metadata":{},"source":["Fiting a logistic regression model with regularization.\n","Using `VotingClassifier`, fitinh the logistic regression model along with either the GratientBoostedClassifier or the AdaBoost model.\n","Determing the error as before and compare the results to the appropriate gradient boosted model(s)."]},{"cell_type":"code","execution_count":null,"id":"f0a14f11-5c1e-4e0d-80d9-416f0885077a","metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# L2 regularized logistic regression\n","LR_L2 = LogisticRegression(penalty='l2', max_iter=500, solver='saga').fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"5c57ea43-41fd-4643-b76f-0fb61597a986","metadata":{},"outputs":[],"source":["y_pred = LR_L2.predict(X_test)\n","print(classification_report(y_pred, y_test))"]},{"cell_type":"code","execution_count":null,"id":"2ccb7e64-51b5-47a8-ab6b-c31ad65f8e4b","metadata":{},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred)\n","sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n","plt.show()"]},{"cell_type":"markdown","id":"75f55a84-857b-4edb-a028-e5a42ac20944","metadata":{},"source":["Stacked model.\n"]},{"cell_type":"code","execution_count":null,"id":"fc04bdbf-e7e0-44b8-bc03-b7c07387421f","metadata":{},"outputs":[],"source":["from sklearn.ensemble import VotingClassifier\n","\n","# The combined model--logistic regression and gradient boosted trees\n","estimators = [('LR_L2', LR_L2), ('GBC', GV_GBC)]\n","\n","VC = VotingClassifier(estimators, voting='soft')\n","VC = VC.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"37296ecb-1559-4bbe-9e20-795017ce6226","metadata":{},"outputs":[],"source":["y_pred = VC.predict(X_test)\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"id":"6b49671f-2fb4-4531-97f1-cd41bd7d9d66","metadata":{},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred)\n","sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n","plt.show()\n","#sns.set_context('talk')\n","#cm = confusion_matrix(y_test, y_pred)\n","#ax = sns.heatmap(cm, annot=True, fmt='d')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
